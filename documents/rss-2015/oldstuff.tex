\section{General Robotic Autonomous Training Algorithm}
\label{sec:training}
We teach the system by finding its weaknesses and training it to overcome them.

Our framework structures the training in a way that scales. 

When the robot asks for help, we can ground ambiguous object examples to the right class
and retrain the models online.

\subsection{GRATA Definition}

In the following algorithm design pattern, 
$X$ is the set of ground truth labels for the specified problem,
$Y$ is the set of all possible observations for the specified problem,
\mbox{$D \subset X \times Y$} is the set of all possible training pairs observable in our problem instance,
\mbox{$\{T_i\}_{i \in \mathbb{N}}$} is a sequence of curated sets of training examples (where \mbox{$\forall i \in \mathbb{N}, T_i \subset D$}),  
$\mathcal{T}$ is the power set of $D$,
\mbox{$O: \mathcal{T} \to \mathbb{R}$} is the objective function that we are trying to optimize 
(which includes the implementation of the physical actions the robot must take to evaluate it),
\mbox{$S: \mathbb{N} \to \mathbb{R}$} is the objective function history (i.e. \mbox{$S(i) = O(T_i)$}),
$\mathcal{S}$ is the set of all possible objective function histories,
\mbox{$H: \mathcal{S} \times \mathbb{N} \to \{0,1\}$} is a function which decides whether to ask for help at
a specified time step,
\mbox{$\mathcal{C} = \mathcal{T} \times \mathcal{S} \times \mathbb{N}$} is the complete training state,
\mbox{$G: \mathcal{C}$} is a function which implements asking for and receiving help (e.g. auditing and grounding data under bad conditions
or asking for a new collections strategy or a crucial example),
\mbox{$P: \mathcal{C} \to \{0,1\}$} is a function that evaluates a stopping criterion and decides whether to continue training,
and \mbox{$L: \mathcal{C} \to D$} a function that proposes a new ground truth $x \in X$ and collects a corresponding observation $y \in Y$ to form
a new training example \mbox{$(x,y) = d \in D$}. 

\begin{table}
  \begin{center}
  \caption{The list of symbols we use in the definition of GRATA.}
  \begin{tabular}{lr}
    \toprule
    Symbol & Meaning \\ 
    \midrule
    $X$  & Ground Truth Labels \\
    $Y$  & Observations \\
    $D \subset X \times Y$  & Universe of Observable Data \\
    $\{T_i\}_{i \in \mathbb{N}}$  & Sequence of Training Sets \\
    $\mathcal{T} = 2^D$ & All Possible Training Sets \\
    $O: \mathcal{T} \to \mathbb{R}$ & Objective Function \\
    $S: \mathbb{N} \to \mathbb{R}$  & Objective Function History \\
    $\mathcal{S} = \{S: \mathbb{N} \to \mathbb{R}\}$  & All Possible Objective Function Histories \\
    $H: \mathcal{S} \times \mathbb{N} \to \{0,1\}$  & Help Criterion \\
    $\mathcal{C} = \mathcal{T} \times \mathcal{S} \times \mathbb{N}$  & Complete Training Set \\
    $G: \mathcal{C}$  & Help Request \\
    $P: \mathcal{C} \to \{0,1\}$  & Stopping Criterion \\
    $L: \mathcal{C} \to D$  & Sample Proposal \\
  \bottomrule
  \end{tabular}
  \end{center}
\end{table}



Applying GRATA to a problem involves defining the above quantities and implementing the high level algorithm
in the figure ~\citep{}.

\begin{figure}
  \textbf{GRATA}
  \begin{algorithmic}
  \STATE $t\gets 1$
  \STATE $c\gets 1$
  \STATE $T_1 = \emptyset$
  \STATE $S(1)\gets 0$
  \STATE $i\gets 1$
  \WHILE{$c$}
    \IF {$H(S,i) == 1$}
      \STATE $G(T_i, S,i)$
    \ELSE
      \STATE $d\gets L(T_i, S, i)$
      \STATE $T_{i+1}\gets T_i \cup \{d\}$
    \ENDIF
    \STATE $i\gets i+1$
    \STATE $S(i)\gets O(T_i)$
    \STATE $c\gets P(T_i, S, i)$
  \ENDWHILE
  \end{algorithmic}
  \caption{The high-level generalized robotic automatic training algorithm (GRATA) which we employ.}
\end{figure}

\subsection{GRATA Simulation}
Understanding the behavior of GRATA requires running the system many times. This would be impractical
to do on the actual robot. It is necessary use a simulator for the process so that we can dramatically shorten the
experimental iteration time. A dense sampling strategy is a good baseline and the data collected can
be queried by an active learning technique to simulate the process of data collection.

Using a dense sampling strategy, we approximate the set $D$ and can then run offline experiments using other
sampling strategies. However, the numbers we report are on actual executions of the system where
the robot gathers the data online.


\section{Applications of GRATA}

\subsection{Recognition Training}

\subsection{Pose Estimation Training}

\subsection{Grasp Training}
4. Once aiming is complete, save the image in the reticle, try to grasp, and save whether that grasp completed.
This can be ascertained by the gripper position.

5. Calculate a density map for this 

\subsection{PID Parameter Training}

